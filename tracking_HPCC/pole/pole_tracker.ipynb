{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import sys\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import keras\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('/home/mvdokh/tracking/')\n",
    "sys.path.append('/home/mvdokh/tracking/DeepLearningUtils')\n",
    "\n",
    "from utils import augmenters\n",
    "\n",
    "from DeepLearningUtils.src.DeepLearningUtils.TrainingData.Keypoint.keypoint_data_generator import KeypointDataGenerator\n",
    "from DeepLearningUtils.src.DeepLearningUtils.Optimizers.keras_schedulers import CosineDecayWithWarmup\n",
    "\n",
    "from DeepLearningUtils.keras_unet_collection import models\n",
    "\n",
    "from pole_tracker import MetricsLoggerCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = '/home/mvdokh/data/'\n",
    "\n",
    "checkpoint_path = 'Tip+Curve+Ryan.weights.h5'\n",
    "\n",
    "num_classes = 1\n",
    "\n",
    "input_shape = (256, 256, 3)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "augmentation = augmenters.create_contact_augmentation()\n",
    "\n",
    "# Create output directory for training artifacts\n",
    "output_dir = Path(__file__).parent / 'training_outputs' if '__file__' in globals() else Path('./training_outputs')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_data, training_labels) = pickle.load(open(training_path + 'training_data.pkl', 'rb'))\n",
    "(validation_data, validation_labels) = pickle.load(open(training_path + 'testing_data.pkl', 'rb'))\n",
    "\n",
    "training_generator = KeypointDataGenerator(training_data,\n",
    "                                             training_labels,\n",
    "                                             augmentation=augmentation,\n",
    "                                             batch_size=BATCH_SIZE, training=True, )\n",
    "validation_generator = KeypointDataGenerator(validation_data, validation_labels, batch_size=BATCH_SIZE,\n",
    "                                               training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter_num=[64, 128, 256, 512, 1024] #256 -> 128 -> 64 -> 32 -> 16\n",
    "filter_num=[64, 64,64, 64, 64, 64] \n",
    "#filter_num=[64, 64,64, 128, 128, 128] \n",
    "\n",
    "model = models.att_unet_2d(input_shape, \n",
    "                           filter_num=filter_num, \n",
    "                           n_labels=num_classes, \n",
    "                           stack_num_down=2, \n",
    "                           stack_num_up=2, \n",
    "                           activation='ReLU', \n",
    "                           atten_activation='ReLU', \n",
    "                           attention='add', \n",
    "                           output_activation='Sigmoid', #For multi-class use Softmax\n",
    "                           batch_norm=True, \n",
    "                           dropout=True,\n",
    "                           dropout_rate=0.1,\n",
    "                           l2_regularization=False,\n",
    "                           l2_weight=1e-4,\n",
    "                           pool=False, #Uses strided convolutions instead of max pooling\n",
    "                           unpool=False, #Uses transposed convolutions instead of upsampling\n",
    "                           backbone='EfficientNetB1',\n",
    "                           weights='imagenet', \n",
    "                           freeze_backbone=True, \n",
    "                           freeze_batch_norm=True, \n",
    "                           name='attunet')\n",
    "                           \n",
    "inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "x = keras.applications.efficientnet.preprocess_input(inputs)\n",
    "\n",
    "outputs = model(x)\n",
    "\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_scheduler = CosineDecayWithWarmup(\n",
    "    initial_learning_rate=1e-5,\n",
    "    final_learning_rate=1e-4,\n",
    "    n_warmup_steps=150*5,\n",
    "    n_cosine_steps=100000,\n",
    ")\n",
    "adamopt = keras.optimizers.AdamW(\n",
    "        learning_rate=warmup_scheduler,\n",
    "        clipnorm=0.1,\n",
    "        #weight_decay=0.1,\n",
    "    )\n",
    "\n",
    "# TensorBoard for detailed monitoring\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"./training_outputs/tensorboard\",\n",
    "    write_graph=True,\n",
    "    write_images=True,\n",
    "    histogram_freq=1,\n",
    "    update_freq='epoch'\n",
    ")\n",
    "\n",
    "# Save best model weights\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=str(checkpoint_path),\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    patience=10,\n",
    "    restore_best_weights=True)\n",
    "\n",
    "# Custom metrics logger for persistent tracking\n",
    "metrics_logger_callback = MetricsLoggerCallback(\n",
    "    output_dir=output_dir,\n",
    "    metrics_filename='training_metrics.json',\n",
    "    plot_filename='training_progress.png'\n",
    ")\n",
    "\n",
    "# Learning rate reduction on plateau\n",
    "#reduce_lr_callback = keras.callbacks.ReduceLROnPlateau(\n",
    "#    monitor='val_loss',\n",
    "#    factor=0.5,\n",
    "#    patience=5,\n",
    "#    min_lr=1e-7,\n",
    "#    verbose=1\n",
    "#)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=adamopt,\n",
    "    loss='mean_squared_error',\n",
    "    metrics=[\n",
    "             ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 302ms/step - loss: 4.4397e-04 - val_loss: 4.4673e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 2/150\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 249ms/step - loss: 3.7247e-04 - val_loss: 4.4152e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 3/150\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 234ms/step - loss: 3.6080e-04 - val_loss: 4.3948e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 4/150\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 237ms/step - loss: 3.5990e-04 - val_loss: 4.3936e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 5/150\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 247ms/step - loss: 3.6807e-04 - val_loss: 4.1437e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 6/150\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 3.4628e-04\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 235ms/step - loss: 3.4625e-04 - val_loss: 3.8359e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 7/150\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 234ms/step - loss: 3.2702e-04 - val_loss: 3.3131e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 8/150\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 229ms/step - loss: 3.0214e-04 - val_loss: 3.1473e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 9/150\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 222ms/step - loss: 3.0966e-04 - val_loss: 3.3625e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 10/150\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 223ms/step - loss: 2.9954e-04 - val_loss: 3.2668e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 11/150\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 220ms/step - loss: 2.8800e-04 - val_loss: 3.0643e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 12/150\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 2.8588e-04\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 211ms/step - loss: 2.8587e-04 - val_loss: 3.0714e-04 - learning_rate: 5.0000e-05\n",
      "Epoch 13/150\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 212ms/step - loss: 2.8400e-04 - val_loss: 3.1413e-04 - learning_rate: 2.5000e-05\n",
      "Epoch 14/150\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 215ms/step - loss: 2.7383e-04 - val_loss: 2.9798e-04 - learning_rate: 2.5000e-05\n",
      "Epoch 15/150\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 227ms/step - loss: 2.7218e-04 - val_loss: 2.9859e-04 - learning_rate: 2.5000e-05\n",
      "Epoch 16/150\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 215ms/step - loss: 2.7322e-04 - val_loss: 3.0809e-04 - learning_rate: 2.5000e-05\n",
      "Epoch 17/150\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 2.7376e-04\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 225ms/step - loss: 2.7373e-04 - val_loss: 3.0733e-04 - learning_rate: 2.5000e-05\n",
      "Epoch 18/150\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 224ms/step - loss: 2.6675e-04 - val_loss: 2.8100e-04 - learning_rate: 1.2500e-05\n",
      "Epoch 19/150\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 210ms/step - loss: 2.7278e-04 - val_loss: 2.9391e-04 - learning_rate: 1.2500e-05\n",
      "Epoch 20/150\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 221ms/step - loss: 2.7082e-04 - val_loss: 2.9967e-04 - learning_rate: 1.2500e-05\n",
      "Epoch 21/150\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 212ms/step - loss: 2.6496e-04 - val_loss: 2.8664e-04 - learning_rate: 1.2500e-05\n",
      "Epoch 22/150\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 2.6036e-04\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 210ms/step - loss: 2.6038e-04 - val_loss: 2.9751e-04 - learning_rate: 1.2500e-05\n",
      "Epoch 23/150\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 208ms/step - loss: 2.6285e-04 - val_loss: 2.9099e-04 - learning_rate: 6.2500e-06\n",
      "Epoch 24/150\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 214ms/step - loss: 2.5756e-04 - val_loss: 2.8465e-04 - learning_rate: 6.2500e-06\n",
      "Epoch 25/150\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 209ms/step - loss: 2.5656e-04 - val_loss: 2.8805e-04 - learning_rate: 6.2500e-06\n",
      "Epoch 26/150\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 216ms/step - loss: 2.5585e-04 - val_loss: 2.9121e-04 - learning_rate: 6.2500e-06\n",
      "Epoch 27/150\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 2.5874e-04\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 212ms/step - loss: 2.5875e-04 - val_loss: 2.8835e-04 - learning_rate: 6.2500e-06\n",
      "Epoch 28/150\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 211ms/step - loss: 2.6409e-04 - val_loss: 2.9141e-04 - learning_rate: 3.1250e-06\n"
     ]
    }
   ],
   "source": [
    "epochs = 150\n",
    "r = model.fit(training_generator,\n",
    "              epochs=epochs,\n",
    "              validation_data=validation_generator,\n",
    "              callbacks=[tensorboard_callback,\n",
    "                         model_checkpoint_callback,\n",
    "                         early_stopping_callback,\n",
    "                         metrics_logger_callback\n",
    "                         ])\n",
    "\n",
    "n_epochs_trained = len(r.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 18:11:11.409549: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-28 18:11:11.604161: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-28 18:11:11.604181: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-28 18:11:11.709234: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-28 18:11:11.815277: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.15.0\n",
      "GPU devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 18:11:22.707432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43622 MB memory:  -> device: 0, name: NVIDIA L40S, pci bus id: 0000:4a:00.0, compute capability: 8.9\n",
      "2025-08-28 18:11:22.719787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 43622 MB memory:  -> device: 1, name: NVIDIA L40S, pci bus id: 0000:61:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix multiplication completed successfully on /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU devices:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Test GPU computation\n",
    "with tf.device('/GPU:0'):\n",
    "    # Create some random large matrices\n",
    "    a = tf.random.normal([10000, 10000])\n",
    "    b = tf.random.normal([10000, 10000])\n",
    "    # Perform matrix multiplication\n",
    "    c = tf.matmul(a, b)\n",
    "print(\"Matrix multiplication completed successfully on\", c.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing TensorFlow 2.19.0 (GPU, bundled CUDA/cuDNN)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-29 10:03:22.511433: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-29 10:03:23.012999: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1756476203.184553 1623911 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1756476203.230240 1623911 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1756476203.620546 1623911 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756476203.620570 1623911 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756476203.620572 1623911 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756476203.620573 1623911 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-29 10:03:23.666191: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.19.0\n",
      "GPU devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "NOTE: If TensorFlow was upgraded, restart the kernel and re-run from the top.\n"
     ]
    }
   ],
   "source": [
    "# Install TensorFlow 2.19.0 GPU wheel with bundled CUDA/cuDNN\n",
    "import sys, subprocess\n",
    "print(\"Installing TensorFlow 2.19.0 (GPU, bundled CUDA/cuDNN)...\")\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", \"--upgrade\", \"tensorflow[and-cuda]==2.19.0\"])  # noqa: E231\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU devices:\", tf.config.list_physical_devices('GPU'))\n",
    "print(\"NOTE: If TensorFlow was upgraded, restart the kernel and re-run from the top.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
